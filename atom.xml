<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WiZardWen</title>
  
  <subtitle>Blog</subtitle>
  <link href="http://wzw21.cn/atom.xml" rel="self"/>
  
  <link href="http://wzw21.cn/"/>
  <updated>2020-12-23T15:32:10.574Z</updated>
  <id>http://wzw21.cn/</id>
  
  <author>
    <name>Zhaowen Wang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ASR (自动语音识别）初探</title>
    <link href="http://wzw21.cn/2020/12/23/asr/"/>
    <id>http://wzw21.cn/2020/12/23/asr/</id>
    <published>2020-12-23T14:43:35.000Z</published>
    <updated>2020-12-23T15:32:10.574Z</updated>
    
    <content type="html"><![CDATA[<h1 id="asr实验及记录"><a class="markdownIt-Anchor" href="#asr实验及记录"></a> ASR实验及记录</h1><h3 id="deepspeech2"><a class="markdownIt-Anchor" href="#deepspeech2"></a> DeepSpeech2</h3><p>DeepSpeech2是一个采用PaddlePaddle平台的端到端自动语音识别引擎的开源项目，具体原理参考论文Baidu’s Deep Speech 2 paper。</p><h4 id="环境配置"><a class="markdownIt-Anchor" href="#环境配置"></a> 环境配置</h4><ul><li>使用官方镜像，运行失败。原因：PaddlePaddle版本不匹配，缺少RNN模块等关键组件；尝试进行修改后发现CUDNN版本也不匹配；</li><li>使用带有正确版本CUDA与CUDNN的镜像，手动安装PaddlePaddle，安装成功后clone DeepSpeech2项目，根据setup.sh进行相关依赖的安装与配置。注意镜像中缺少git、swig等基础命令或依赖包的安装，需通过apt-get进行安装。</li></ul><h4 id="数据准备及使用方式"><a class="markdownIt-Anchor" href="#数据准备及使用方式"></a> 数据准备及使用方式：</h4><ul><li><p>下载BaiduCN1.2k Model语音模型与Mandarin LM Small语言模型；</p></li><li><p>自行准备manifest文件，其中包括每条音频的存储路径，音频时长与数据标签（文本）。文本中不能含有标点符号、英文字母与阿拉伯数字。格式为：{“audio_filepath”: “”, “duration”: , “text”: “”}</p></li><li><p>使用如下命令可进行自定义语音音频识别</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">PYTHONIOENCODING&#x3D;utf-8 &#x2F;&#x2F; 需设定编码方式为utf-8，否则会出现错误；</span><br><span class="line"></span><br><span class="line">python infer.py</span><br><span class="line"></span><br><span class="line">--num_samples 1 &#x2F;&#x2F;识别语音条数</span><br><span class="line"></span><br><span class="line">--infer_manifest data&#x2F;mydata&#x2F;manifest &#x2F;&#x2F;manifest文件路径</span><br><span class="line"></span><br><span class="line">--use_gru TRUE &#x2F;&#x2F;使用门控循环单元</span><br><span class="line"></span><br><span class="line">--use_gpu FALSE </span><br><span class="line"></span><br><span class="line">--mean_std_path models&#x2F;baidu_ch1.2k&#x2F;mean_std.npz &#x2F;&#x2F;样本特征的均值与标准差</span><br><span class="line"></span><br><span class="line">--vocab_path models&#x2F;baidu_ch1.2k&#x2F;vocab.txt &#x2F;&#x2F;字典路径</span><br><span class="line"></span><br><span class="line">--lang_model_path models&#x2F;lm&#x2F;zh_giga.no_cna_cmn.prune01244.klm &#x2F;&#x2F;语言模型路径</span><br><span class="line"></span><br><span class="line">--model_path models&#x2F;baidu_ch1.2k &#x2F;&#x2F;语音模型路径</span><br><span class="line"></span><br><span class="line">--num_conv_layers&#x3D;2 &#x2F;&#x2F;卷积层数量</span><br><span class="line"></span><br><span class="line">--num_rnn_layers&#x3D;3 &#x2F;&#x2F;循环神经网络配置</span><br><span class="line"></span><br><span class="line">--rnn_layer_size&#x3D;2048 </span><br><span class="line"></span><br><span class="line">--share_rnn_weights&#x3D;False </span><br><span class="line"></span><br><span class="line">--specgram_type&#x3D;&#39;linear&#39; </span><br><span class="line"></span><br><span class="line">--error_rate_type&#x3D;cer &#x2F;&#x2F;错误率类型设置为字错误率</span><br><span class="line"></span><br><span class="line">--alpha&#x3D;0.4 </span><br><span class="line"></span><br><span class="line">--beta&#x3D;0.3</span><br></pre></td></tr></table></figure></li><li><p>使用tools/tune.py可使用不同参数进行识别，以找出最优参数。参数包括alpha与beta，分别为语言模型权重与单词插入权重。</p></li><li><p>使用tools/compute_mean_std.py和tools/build_vocab.py可获得自定义样本的特征均值、标准差（用于归一化）与字典；</p></li><li><p>相关命令及运行参数保存在command.txt中，方便使用。</p></li></ul><h4 id="实验结果分析"><a class="markdownIt-Anchor" href="#实验结果分析"></a> 实验结果分析</h4><ul><li>实验数据为100条语音数据，带有ground truth。使用BaiduCN1.2k Model语音模型与Mandarin LM Small语言模型，使用预训练模型的数据特征（即归一化方式）与字典，经测试，最佳运行参数为alpha=0.4， beta =0.3，测试结果的平均cer（字错误率）为55.19%</li><li>将语音模型替换为Aishell模型进行实验，错误率升高</li></ul><h4 id="迁移学习"><a class="markdownIt-Anchor" href="#迁移学习"></a> 迁移学习</h4><p>在公开的模型上使用自己的数据集进行迁移训练</p><ul><li><p>准备工作</p><p>1）修改词典中的阿拉伯数字为中文；</p><p>2）将正确数据标签中所有阿拉伯数字换为中文，去除所有标点符号与英文字母；</p><p>3）按照要求生成manifest.train文件，包含训练数据路径，时长与标签；</p><p>4）预处理出训练集数据特征的均值与标准差；</p><p>5）若要修改字典（添加或删除），则需要修改神经网络模型的结构，较为复杂；</p></li><li><p>运行train.py进行训练，命令及参数如下</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">PYTHONIOENCODING&#x3D;utf-8 </span><br><span class="line"></span><br><span class="line">python train.py </span><br><span class="line"></span><br><span class="line">--batch_size 16 &#x2F;&#x2F;批量大小</span><br><span class="line"></span><br><span class="line">--num_epoch 10 &#x2F;&#x2F;训练周期数</span><br><span class="line"></span><br><span class="line">--num_conv_layers&#x3D;2 </span><br><span class="line"></span><br><span class="line">--num_rnn_layers&#x3D;3 </span><br><span class="line"></span><br><span class="line">--rnn_layer_size&#x3D;2048 </span><br><span class="line"></span><br><span class="line">--share_rnn_weights&#x3D;False </span><br><span class="line"></span><br><span class="line">--save_epoch 1 &#x2F;&#x2F;每训练一个epoch进行一次模型保存</span><br><span class="line"></span><br><span class="line">--num_samples 80 </span><br><span class="line"></span><br><span class="line">--learning_rate 0.05 &#x2F;&#x2F;学习率，需调优</span><br><span class="line"></span><br><span class="line">--max_duration 130 &#x2F;&#x2F;最大音频时长</span><br><span class="line"></span><br><span class="line">--use_gpu FALSE </span><br><span class="line"></span><br><span class="line">--use_gru TRUE </span><br><span class="line"></span><br><span class="line">--init_from_pretrained_model models&#x2F;baidu_ch1.2k </span><br><span class="line"></span><br><span class="line">--train_manifest data&#x2F;mydata&#x2F;manifest.train &#x2F;&#x2F;训练集路径</span><br><span class="line"></span><br><span class="line">--dev_manifest data&#x2F;mydata&#x2F;manifest.validation &#x2F;&#x2F;验证集路径</span><br><span class="line"></span><br><span class="line">--mean_std_path models&#x2F;baidu_ch1.2k&#x2F;mean_std.npz &#x2F;&#x2F;可选择模型预训练时使用的数据的特征（即models&#x2F;baidu_ch1.2k&#x2F;mean_std.npz），或是当前进行迁移学习的数据的特征（data&#x2F;mydata&#x2F; mean_std.npz）</span><br><span class="line"></span><br><span class="line">--vocab_path models&#x2F;baidu_ch1.2k&#x2F;vocab_new.txt </span><br><span class="line"></span><br><span class="line">--output_model_dir models&#x2F;baidu_ch1.2k_new &#x2F;&#x2F;新模型保存位置</span><br><span class="line"></span><br><span class="line">--num_iter_print 1 &#x2F;&#x2F;每一个epoch输出一次信息</span><br><span class="line"></span><br><span class="line">--test_off TRUE&#x2F;&#x2F;训练过程中是否进行验证</span><br></pre></td></tr></table></figure></li></ul><h4 id="难点"><a class="markdownIt-Anchor" href="#难点"></a> 难点</h4><ul><li>环境难以配置，官方镜像存在问题，配置环境花费大量时间；</li><li>暂无法成功在docker中使用gpu，导致训练与识别速度非常慢；</li><li>（15h仅训练了6个epoch）</li><li>自定义训练数据的特征均值和标准差与预训练模型使用的数据不同，导致迁移学习效果较差</li><li>若需修改字典，则必须深入了解DeepSpeech模型结构与修改方式，深入学习PaddlePaddle框架</li></ul><h4 id="todo"><a class="markdownIt-Anchor" href="#todo"></a> Todo</h4><ul><li>结合预训练时使用的数据的特征，对我们的音频数据进行预处理，再进行迁移训练</li><li>修改字典，修改网络模型，使最后的全连接层与自定义字典相匹配</li><li>使用更大型的语言模型Mandarin LM Large</li></ul><h4 id="参考文档"><a class="markdownIt-Anchor" href="#参考文档"></a> 参考文档</h4><ul><li><p><a href="https://github.com/PaddlePaddle/DeepSpeech/blob/develop/README_cn.md">https://github.com/PaddlePaddle/DeepSpeech/blob/develop/README_cn.md</a></p></li><li><p><a href="https://www.paddlepaddle.org.cn/install/quick">https://www.paddlepaddle.org.cn/install/quick</a></p></li><li><p><a href="https://baijiahao.baidu.com/s?id=1675202226359497084&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1675202226359497084&amp;wfr=spider&amp;for=pc</a></p></li></ul><h3 id="cvte开源模型"><a class="markdownIt-Anchor" href="#cvte开源模型"></a> CVTE开源模型</h3><h4 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h4><ul><li>基于Kaldi</li><li>批量将mp3或wav音频进行数据部署，并生成txt识别结果</li><li>无phone和ctm时间戳</li></ul><h4 id="实验过程"><a class="markdownIt-Anchor" href="#实验过程"></a> 实验过程</h4><ul><li>将音频文件放入data/wav/filename中</li><li>新建data/filename/test文件夹，并在其中创建text、utt2spk、spk2utt、wav.scp文件，text中保存标签数据，wav.scp中保存音频路径，utt2spk、spk2utt中保存音频与说话人的关系。</li><li>每次运行后需删除data/filename/test中的cmvn.scp文件，否则会报错。</li><li>创建好data/filename/test中相应文件后，可使用utils/validate_data_dir.sh进行检查（需加上 --no-feats）</li><li>运行run.sh开始语音识别，运行前需修改run.sh中的路径（有三处）</li><li>在exp/chain/tdnn/decode_filename/scoring_kaldi/中可查看识别结果，对于不同的参数会有不同的结果，可通过best_cer（best_wer）查看最优结果对应参数（记为参数a）参数包括inv-acoustic-scale∈[7,17] ，word-ins-penalty∈{0.0,0.5,1.0}。</li><li>猜测：最优识别结果对应的参数（参数a）是最适合对此类语音数据进行识别的参数。在没有text文件的情况下，最优结果大概率存在于使用参数a得到的结果中。</li><li>对于不同的数据集，需要进行测试以获取最优参数</li></ul><h4 id="实验结果分析-2"><a class="markdownIt-Anchor" href="#实验结果分析-2"></a> 实验结果分析</h4><ul><li>实验数据为28条语音数据，带有ground truth。经测试，最佳参数为inv-acoustic-scale=16， word-ins-penalty=0.0，测试结果的平均cer（字错误率）为50.18%</li></ul><h4 id="流程"><a class="markdownIt-Anchor" href="#流程"></a> 流程</h4><ul><li>将音频文件（wav格式）放入/kaldi-master/egs/cvte/s5/data/wav/filename中；</li><li>将text文件放入/kaldi-master/egs/cvte/s5/data/test_filename/test中，text格式为“音频ID    文字标签\r\n”（中间为Tab）；</li><li>将conf与frame_shift放入test文件夹；</li><li>将进行整个识别流程封装入asr.sh文件。首先将自动生成wav.scp、utt2spk、spk2utt文件，并删除可能造成冲突的文件，然后开始语音识别；</li><li>识别结果将保存于/kaldi-master/egs/cvte/s5/exp/chain/tdnn/decode_filename/scoring_kaldi/中。若text文件中含有真实标签，则可查看最佳参数。打开最佳参数对应的文件夹可查看识别结果。</li></ul><h4 id="难点-2"><a class="markdownIt-Anchor" href="#难点-2"></a> 难点</h4><ul><li>无官方文档，相关参考资料较少</li><li>模型封装完整，无法进行修改，无法使用迁移学习进行模型优化</li><li>因未提供相关解码文件，无法获取时间戳信息</li></ul><h4 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h4><ul><li><p><a href="https://chatopera.blog.csdn.net/article/details/107733688">https://chatopera.blog.csdn.net/article/details/107733688</a></p></li><li><p><a href="https://blog.csdn.net/samurais/article/details/107889376">https://blog.csdn.net/samurais/article/details/107889376</a></p></li><li><p><a href="https://blog.csdn.net/tcx1992/article/details/85717100">https://blog.csdn.net/tcx1992/article/details/85717100</a></p></li><li><p><a href="https://github.com/tcxdgit/ASR_utils">https://github.com/tcxdgit/ASR_utils</a></p></li><li><p><a href="https://blog.csdn.net/benbenls/article/details/102691710">https://blog.csdn.net/benbenls/article/details/102691710</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;asr实验及记录&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#asr实验及记录&quot;&gt;&lt;/a&gt; ASR实验及记录&lt;/h1&gt;
&lt;h3 id=&quot;deepspeech2&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#</summary>
      
    
    
    
    <category term="操作实践" scheme="http://wzw21.cn/categories/%E6%93%8D%E4%BD%9C%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="ASR" scheme="http://wzw21.cn/tags/ASR/"/>
    
  </entry>
  
  <entry>
    <title>Python使用建议</title>
    <link href="http://wzw21.cn/2020/12/23/tips4python/"/>
    <id>http://wzw21.cn/2020/12/23/tips4python/</id>
    <published>2020-12-23T07:54:26.000Z</published>
    <updated>2020-12-23T14:07:43.854Z</updated>
    
    <content type="html"><![CDATA[<h2 id="强烈推荐python组合技-miniconda-jupyter-vscode"><a class="markdownIt-Anchor" href="#强烈推荐python组合技-miniconda-jupyter-vscode"></a> 强烈推荐Python组合技 : MiniConda + Jupyter + Vscode</h2><h2 id="管理python环境"><a class="markdownIt-Anchor" href="#管理python环境"></a> 管理Python环境</h2><p>使用miniconda管理python环境，方便不同python版本的管理与切换，同时方便对python库进行管理与使用。例如你可以创建一个python版本为3.7的环境来进行tensorflow的使用，创建一个python版本为3.8的环境来进行pytorch的使用，两个环境独立，互不影响。</p><h2 id="实时运行代码"><a class="markdownIt-Anchor" href="#实时运行代码"></a> 实时运行代码</h2><p>使用Jupyter Notebook来进行程序编写，可以实时运行代码。每完成几行代码后，同时按下enter与shift，可直接运行这几行代码并得到结果，并且结果会保存在内存中，可继续编写程序。</p><h2 id="合适的ide"><a class="markdownIt-Anchor" href="#合适的ide"></a> 合适的IDE</h2><p>使用全能的Vscode搭配miniconda与jupyter进行python程序的编写，比起在网页上使用jupyter notebook更加舒适。在Vscode的右上角可更改所使用的python环境。</p><p>具体的安装方式与环境配置方式待补充。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;强烈推荐python组合技-miniconda-jupyter-vscode&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#强烈推荐python组合技-miniconda-jupyter-vscode&quot;&gt;&lt;/a&gt; 强烈推荐Python组</summary>
      
    
    
    
    <category term="经验与总结" scheme="http://wzw21.cn/categories/%E7%BB%8F%E9%AA%8C%E4%B8%8E%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="总结" scheme="http://wzw21.cn/tags/%E6%80%BB%E7%BB%93/"/>
    
    <category term="Python" scheme="http://wzw21.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>律学初探</title>
    <link href="http://wzw21.cn/2020/11/10/lvxue1/"/>
    <id>http://wzw21.cn/2020/11/10/lvxue1/</id>
    <published>2020-11-10T08:43:31.000Z</published>
    <updated>2020-12-23T07:49:17.084Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概论"><a class="markdownIt-Anchor" href="#概论"></a> 概论</h1><p>律学（temperament）是对构成乐制的各音依据声学原理、运用数学方法来研究各音间相互关系的一门学科。其中，“律”是构成律制的基本单位。当各律在高度上作精密规定，形成一种体系时，称为“律制”（tuning system）。“律”和“音”的概念相近但略有不同，律制中每个单位称为“律”，而音阶中每个单位称为“音”，律制与音阶的关系十分密切。</p><p>我们知道，在复合音中，除“基音”（fundamental tone）外还有各种“泛音”（overtone），有时也称为倍音。以弦振动为例，全弦振动产生基音，同时各部分振动产生各种泛音（弦分两段振动产生第一泛音，分三段振动产生第二泛音，以此类推）。将基音和各泛音进行横向排列，可以得到“分音列”，也称为“谐音列”，如表1-1所示。各律制的规定与分音列密不可分。</p><center>表1-1 分音列</center><table><thead><tr><th style="text-align:center">第一分音</th><th style="text-align:center">第二分音</th><th style="text-align:center">第三分音</th><th style="text-align:center">第四分音</th><th style="text-align:center">第五分音</th><th style="text-align:center">……</th><th style="text-align:center">第N分音</th></tr></thead><tbody><tr><td style="text-align:center">基音</td><td style="text-align:center">第一泛音</td><td style="text-align:center">第二泛音</td><td style="text-align:center">第三泛音</td><td style="text-align:center">第四泛音</td><td style="text-align:center">……</td><td style="text-align:center">第N-1泛音</td></tr><tr><td style="text-align:center">f（频率）</td><td style="text-align:center">2f</td><td style="text-align:center">3f</td><td style="text-align:center">4f</td><td style="text-align:center">5f</td><td style="text-align:center">……</td><td style="text-align:center">N×f</td></tr></tbody></table><p>接下来将分别对音律计算法，三种常见律制（五度相生律、纯律和十二平均律），中欧律学简史以及律制的应用进行详细介绍。</p><h1 id="以下内容暂不开放"><a class="markdownIt-Anchor" href="#以下内容暂不开放"></a> 以下内容暂不开放</h1><h1 id="音律计算法"><a class="markdownIt-Anchor" href="#音律计算法"></a> 音律计算法</h1><p>音律计算法即音程的计算法，使用频率比或音程值（interval value）来表示和计算音程的大小。音程值有四种，分别为对数值、八度值、音分值和平均音程值。</p><h2 id="频率比"><a class="markdownIt-Anchor" href="#频率比"></a> 频率比</h2><h2 id="对数值"><a class="markdownIt-Anchor" href="#对数值"></a> 对数值</h2><h2 id="八度值"><a class="markdownIt-Anchor" href="#八度值"></a> 八度值</h2><h2 id="音分值"><a class="markdownIt-Anchor" href="#音分值"></a> 音分值</h2><h2 id="平均音程值"><a class="markdownIt-Anchor" href="#平均音程值"></a> 平均音程值</h2><h1 id="五度相生律"><a class="markdownIt-Anchor" href="#五度相生律"></a> 五度相生律</h1><h1 id="纯律"><a class="markdownIt-Anchor" href="#纯律"></a> 纯律</h1><h1 id="十二平均律"><a class="markdownIt-Anchor" href="#十二平均律"></a> 十二平均律</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概论&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#概论&quot;&gt;&lt;/a&gt; 概论&lt;/h1&gt;
&lt;p&gt;律学（temperament）是对构成乐制的各音依据声学原理、运用数学方法来研究各音间相互关系的一门学科。其中，“律”是构成律制的基本单位。当各</summary>
      
    
    
    
    <category term="理论知识" scheme="http://wzw21.cn/categories/%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86/"/>
    
    
    <category term="乐理" scheme="http://wzw21.cn/tags/%E4%B9%90%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>技术栈</title>
    <link href="http://wzw21.cn/2020/11/10/used/"/>
    <id>http://wzw21.cn/2020/11/10/used/</id>
    <published>2020-11-10T05:09:09.000Z</published>
    <updated>2020-12-23T08:25:49.366Z</updated>
    
    <content type="html"><![CDATA[<h1 id="已掌握或使用过的工具与技术"><a class="markdownIt-Anchor" href="#已掌握或使用过的工具与技术"></a> 已掌握或使用过的工具与技术</h1><h2 id="ide"><a class="markdownIt-Anchor" href="#ide"></a> IDE</h2><ul><li>Free Pascal</li><li>Delphi</li><li>Dev C++</li><li>Virtual Studio 2013/2017</li><li>Virtual Studio Code</li><li>Eclipse</li><li>IntelliJ IDEA</li><li>Pycharm</li><li>Android Studio</li><li>Matlab</li><li>Masm</li></ul><h2 id="语言"><a class="markdownIt-Anchor" href="#语言"></a> 语言</h2><ul><li>Pascal</li><li>C/C++</li><li>Python</li><li>Java</li><li>SQL</li></ul><h2 id="机器学习相关"><a class="markdownIt-Anchor" href="#机器学习相关"></a> 机器学习相关</h2><ul><li>TensorFlow</li><li>Keras</li><li>Opencv</li><li>Scikit-Learn</li><li>ModelArts</li><li>Kaldi</li><li>DeepSpeech</li></ul><h2 id="数据库"><a class="markdownIt-Anchor" href="#数据库"></a> 数据库</h2><ul><li>SQL Server 2000</li><li>MySQL</li><li>Navicat</li></ul><h2 id="cjava-框架"><a class="markdownIt-Anchor" href="#cjava-框架"></a> C++/Java 框架</h2><ul><li>MFC</li><li>Win32 API</li><li>Spring Boot</li><li>MyBatis</li></ul><h2 id="硬件"><a class="markdownIt-Anchor" href="#硬件"></a> 硬件</h2><ul><li>Raspberry Pi</li><li>Serial Comm</li><li>ESP 8266</li><li>MPU 6050</li><li>8253/8255/8259</li></ul><h2 id="前端"><a class="markdownIt-Anchor" href="#前端"></a> 前端</h2><ul><li>Vue.js</li><li>Bootstrap</li><li>Hexo</li></ul><h2 id="其它工具"><a class="markdownIt-Anchor" href="#其它工具"></a> 其它工具</h2><h3 id="音乐制作"><a class="markdownIt-Anchor" href="#音乐制作"></a> 音乐制作</h3><ul><li>Cubase</li><li>Overture</li><li>Sonic Pi</li></ul><h3 id="游戏制作"><a class="markdownIt-Anchor" href="#游戏制作"></a> 游戏制作</h3><ul><li>Cocos</li><li>Unity</li></ul><h3 id="图像处理"><a class="markdownIt-Anchor" href="#图像处理"></a> 图像处理</h3><ul><li>Photoshop</li></ul><h3 id="网页制作"><a class="markdownIt-Anchor" href="#网页制作"></a> 网页制作</h3><ul><li>DreamWeaver</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;已掌握或使用过的工具与技术&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#已掌握或使用过的工具与技术&quot;&gt;&lt;/a&gt; 已掌握或使用过的工具与技术&lt;/h1&gt;
&lt;h2 id=&quot;ide&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; </summary>
      
    
    
    
    <category term="经验与总结" scheme="http://wzw21.cn/categories/%E7%BB%8F%E9%AA%8C%E4%B8%8E%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="总结" scheme="http://wzw21.cn/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://wzw21.cn/2020/11/08/hello-world/"/>
    <id>http://wzw21.cn/2020/11/08/hello-world/</id>
    <published>2020-11-08T05:04:25.660Z</published>
    <updated>2020-11-09T13:43:58.596Z</updated>
    
    <content type="html"><![CDATA[<h2 id="welcome-to-hell"><a class="markdownIt-Anchor" href="#welcome-to-hell"></a> Welcome to Hell</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;welcome-to-hell&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#welcome-to-hell&quot;&gt;&lt;/a&gt; Welcome to Hell&lt;/h2&gt;
</summary>
      
    
    
    
    
  </entry>
  
</feed>
